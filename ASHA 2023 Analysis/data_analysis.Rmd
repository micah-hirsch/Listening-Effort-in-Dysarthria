---
title: "ASHA 2023 Listening Effort Data Analysis"
author: "Micah E. Hirsch"
date: "2023-10-29"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Purpose

The purpose of this document is to run preliminary analyses and visualizations for this project. These results were prepared specifically for a poster presentation at the the 2023 Annual American Speech Language Hearing Association Convention being held in Boston, MA in November 2023.

Any questions or comments regarding this project or analysis may be directed to Micah Hirsch, mhirsch@fsu.edu. 

```{r, include = F, warning = F, message = F}

# Load Needed Packages
library(rio) # install.packages("rio")
library(tidyverse) # install.packages("tidyverse")
# Need remotes package to install gazer and saccades
library(remotes) # install.packages("remotes")
library(gazer) # remotes::install_github("dmirman/gazer")
library(saccades) # remotes::install_github("tmalsburg/saccades/saccades")
library(zoo) # install.packages("zoo")
library(ggpubr) # installl.packages("ggpubr")
library(gt) # install.packages("gt")
library(glmmTMB) # install.packages("glmmTMB")
library(performance) # install.packages("performance")

```

# Descriptive Statistics

## Participant Demographics

First, we will present the demographics of our listeners To date, we recruited 20 listeners to participate in the study. Three listeners were removed from the analysis. One listener decided to withdraw from the study, so their data was removed from the database. For the other two participants, pupillometry data was either not recorded or lost due to instrumental issues. Therefore, for this analysis, we have 17 participants. The descriptive information for these participants are presented below. 

```{r, warning = F, message = F}

# Load in dataset for listener demographics

listener_demo <- rio::import("Cleaned Data/cleaned_listener_demo.csv") 

# Extracting listener gender data

gender <- listener_demo %>%
  dplyr::select(gender) %>%
  dplyr::group_by(gender) %>%
  dplyr::summarize(Frequency = n()) %>%
  dplyr::rename(Category = "gender") %>%
  dplyr::mutate(Group = "Gender",
                Category = fct_relevel(Category, c("woman", "man", "nonbinary"))) %>%
  dplyr::arrange(Category)
  
## Extracting listener race data

race <- listener_demo %>%
  dplyr::select(race) %>%
  dplyr::group_by(race) %>%
  dplyr::summarize(Frequency = n()) %>%
  dplyr::rename(Category = "race") %>%
  dplyr::mutate(Group = "Race",
                Category = fct_relevel(Category, c("white/Caucasian", "Biracial or Multiracial", 
                                                   "race not listed"))) %>%
  dplyr::arrange(Category)

## Extracting listener ethnicity data

ethnicity <- listener_demo %>%
  dplyr::select(ethnicity) %>%
  dplyr::group_by(ethnicity) %>%
  dplyr::summarize(Frequency = n()) %>%
  dplyr::rename(Category = "ethnicity") %>%
  dplyr::mutate(Group = "Ethnicity",
                Category = fct_relevel(Category, c("Hispanic/Latino(a/e)", 
                                                   "Not Hispanic/Latino(a/e)"))) %>%
  dplyr::arrange(Category)

# Creating Demographic Table 1

dplyr::full_join(gender, race) %>%
  dplyr::full_join(., ethnicity) %>%
  # Initiating a gt table
  gt::gt(rowname_col = "Category",
         groupname_col = "Group") 

```

As indicated in the table above, our participants were primarily white/Caucasian, women, and not Hispanic or Latino(a/e). All participants reported no history of a speech, language, or hearing disorder. All participants were fluent English speakers. However, two indicated their native language was different than American English. These languages were Spanish (n=1) and Turkish (n=1).

```{r, warning = F, message = F}

listener_demo %>%
  dplyr::select(c(age)) %>%
  dplyr::summarize(Mean = mean(age), SD = sd(age),
                   Min = min(age), Max = max(age)) %>%
  dplyr::mutate(Category = "Age") %>%
  dplyr::relocate(Category, .before = Mean) %>%
  gt::gt() %>%
  gt::fmt_number(columns = c(Mean, SD),
                decimals = 2) %>%
  gt::cols_label(Category = "")

```

The mean age of the listeners is 26.53 years old. Listener age ranged from 18 to 37 years old.

```{r, include = F, warning = F, message = F}

# Removing unneeded items from the environment

rm(ethnicity, gender, listener_demo, race)

```


## Speaker Intelligibility and Phrase Accuracy

### Mean Speaker Intelligibility

Across all trials in the study, the intelligibility level for each of the speaker is reported below.  Across listeners, the mean intelligibility for the ALS speaker was 81.08% with a standard deviation of 3.86. For the control speaker, the mean intelligibility level was 93.62% with a standard deviation of 2.90.

```{r, warning = F, message = F}

# Load in cleaned data for pupil and perceived listening effort data

data <- rio::import("Cleaned Data/cleaned_data.csv") %>%
  # removing trials with missing rep accuracy: 3 trials removed
  dplyr::mutate(rep_acc = ifelse(rep_acc == "", NA, rep_acc)) %>%
  dplyr::filter(!is.na(rep_acc)) %>%
  # Releveling speaker variable
  dplyr::mutate(speaker = as.factor(speaker),
                speaker = fct_relevel(speaker, "Control", "ALS")) %>%
  # Creating a trial variable that codes trial 6 (i.e. the first experimental trial) as 0.
  dplyr::mutate(trial_c = trial - 6)

# Selecting variables needed to calculate mean speaker intelligibility
intel_df <- data %>%
  dplyr::select(subject, trial, speaker, correct_words, target_number, rep_acc) %>%
  dplyr::distinct()

# Calculating intelligibility for the control and ALS speaker for each listener
intel_byListener <- intel_df %>%
  dplyr::group_by(speaker, subject) %>%
  dplyr::summarize(Intelligibility = sum(correct_words)/sum(target_number)*100)

intel_byListener %>%
  dplyr::group_by(speaker) %>%
  dplyr::summarize("Mean Intelligibility" = mean(Intelligibility), SD = sd(Intelligibility)) %>%
  gt::gt() %>%
  gt::fmt_number(columns = c("Mean Intelligibility", SD),
                 decimals = 2) %>%
  gt::cols_label(speaker = "Speaker")


```

### Phrase Accuracy

For this analysis, we are only looking at the trials that listeners were able to accurately recognize (e.g. 100% intelligible to the listener). Therefore, we are looking at the proportion of trials for each speaker that listeners were able to accurately recognize compared to the total number of trials. Although our ALS speaker's intelligibility was fairly high, only about 49% of all the ALS speaker's trials were accurately recognized across listeners.

```{r, warning = F, message = F}

# Calculating repetition accuracy descriptive data

intel_df %>%
  dplyr::group_by(speaker, rep_acc) %>%
  dplyr::summarize(n = n()) %>%
  tidyr::pivot_wider(names_from = rep_acc,
                     values_from = n) %>%
  dplyr::mutate(percent_accurate = accurate/(accurate + inaccurate)*100) %>%
  dplyr::ungroup() %>%
  gt::gt(rowname_col = "speaker") %>%
  gt::fmt_number(columns = percent_accurate,
                 decimals = 2) %>%
  gt::cols_label(accurate = "Accurate",
                 inaccurate = "Inaccurate",
                 percent_accurate = "Percent Accurate")


```
```{r, include = F, warning = F, message = F}

# removing unneeded items from the environment

rm(intel_byListener, intel_df)

```


# Perceived Listening Effort Ratings

## Descriptives

```{r}

perceived_effort_df <- data %>%
  dplyr::select(subject, trial, speaker, effort_rating, rep_acc, code) %>%
  dplyr::distinct() %>%
  # For this particular analysis, we are just looking at results for accurate repetition
  # However, the final project will look at rep_acc too
  dplyr::filter(rep_acc == "accurate")

per_effort_des <- perceived_effort_df %>%
  dplyr::group_by(speaker) %>%
  dplyr::summarize(per_effort = mean(effort_rating), 
                   sd = sd(effort_rating, na.rm = T),
                   se = sd/sqrt(n()))

per_effort_des

```

### Visualization

```{r}

per_effort_des %>%
  ggplot() +
   aes(x = speaker,
      y = per_effort,
      color = speaker,
      fill = speaker) +
  geom_bar(stat = "identity", alpha = 0.6) +
  geom_errorbar(aes(x = speaker, ymin = per_effort - se, ymax = per_effort + se), width = 0.4) +
  labs(x = "Speaker", y = "Perceived Listening Effort Rating") +
  theme_bw() +
  theme(legend.position = "none", aspect.ratio = 1)

```

## Perceived Listening Effort Model

### Fully Unconditional Model

```{r}

m0 <- glmmTMB(effort_rating ~ 1 + (1|subject) + (1|code), data = perceived_effort_df)

summary(m0)

performance::icc(m0)

```

## Model 1

Adding the centered trial random slope 

```{r}

m1 <- glmmTMB(effort_rating ~ 1 + (trial_c|subject) + (trial_c|code), data = perceived_effort_df)

summary(m1)

anova(m0, m1)

```
## Model 2

Adding trial as a fixed effect

```{r}

m2 <- glmmTMB(effort_rating ~ trial_c + (trial_c|subject) + (trial_c|code), data = perceived_effort_df)

summary(m2)

anova(m1, m2)

```

## Model 3

```{r}

m3 <- glmmTMB(effort_rating ~ trial_c + speaker + (trial_c|subject) + (trial_c|code), data = perceived_effort_df)

summary(m3)

anova(m2, m3)

```

## Final Model

```{r}

per_effort_model_final <- glmmTMB(effort_rating ~ speaker + (trial_c|subject) + (trial_c|code), data = perceived_effort_df)

summary(per_effort_model_final)

# Removing unneeded items from the environment

rm(m0, m1, m2, m3)

```

# Pupil Dilation

## Descriptives and Visualization

```{r}

data %>%
  # For this analysis, we are only looking at accurate repetition trials
  dplyr::filter(rep_acc == "accurate") %>%
  dplyr::group_by(timebins, speaker) %>%
  dplyr::summarize(pupil_dilation = mean(pupil.binned, na.rm = T),
                   pupil_se = sd(pupil.binned, na.rm = T)/sqrt(n())) %>%
  ggplot() +
  aes(x = timebins,
      y = pupil_dilation,
      color = speaker,
      fill = speaker) +
  geom_ribbon(aes(ymin = pupil_dilation - pupil_se, ymax = pupil_dilation + pupil_se), alpha = .3) +
  geom_line() +
  coord_cartesian(xlim = c(0,5000), ylim = c(-100, 200)) +
  labs(x = "Time (ms)", y = "Pupil Dilation (arbitrary units)", fill = "Speaker", color = "Speaker") +
  theme_bw() + 
  theme(legend.position = "bottom", aspect.ratio = 1)

```

# Fully Unconditional Model

First, we ran an unconditional growth model. I first specified a model with the orthogonal polynomials added as fixed effects and subject (i.e. listener) and code (i.e. phrase) as random effects. I also added the orthogonal polynomials as random slopes. I also used the AR(1) covariance structure to specifiy the random effect structure. I was not able to run the model. Therefore, I attempted to respecify the random effect structure by removing the AR(1) specification. This led to a model with singular fit. In response to this, I decided to remove code (i.e.) from the random effect structure in order to simplify it.

```{r}

# Specifying the region of interest for analysis (500 ms to 1000 ms after relative offset of the trial)

pupil_roi <- data %>%
  # For this analysis, we are only analyzing pupil dilation for accurate responses
  dplyr::filter(rep_acc == "accurate") %>%
  # filtering out timebins below 500 (i.e., keeping timebins above 500 ms)
  dplyr::filter(timebins >= 500) %>%
  dplyr::group_by(subject, trial) %>%
  dplyr::filter(timebins <= max(timebins) - 2000) %>%
  ungroup() %>%
  # For the purpose of modeling, we are centering time at 500 ms (i.e. the beginning ROI time)
  dplyr::mutate(time_c = timebins - 500) %>%
  # Rescaling pupil size 
  dplyr::group_by(subject, trial) %>%
  dplyr::mutate(norm_pupil = as.numeric(scale(pupil.binned))) %>%
  dplyr::ungroup()

# Polynomials

pupil_roi <- gazer::code_poly(pupil_roi, predictor = "timebins", poly.order = 3, orthogonal = T, draw.poly = F)

# Exporting region of interest df

rio::export(pupil_roi, "Cleaned Data/pupil_analysis_roi.csv")

## I kept running into issues using glmmTMB, so I switched to lme4

library(lme4)
library(lmerTest)

# specifying unconditional growth model for pupil data

m0 <- lmer(pupil.binned ~ poly1 + poly2 + poly3 +
                (poly1 + poly2 + poly3|subject), 
              data = pupil_roi)

summary(m0)

performance::icc(m0)

```

# Model 1

```{r}

m1 <- lmer(pupil.binned ~ poly1 + poly2 + poly3 + speaker +
                (poly1 + poly2 + poly3|subject), 
              data = pupil_roi)

summary(m1)

anova(m0, m1)

```

## Model 2

```{r}

# Model 2 initially failed to converge, so adding a control statement for bobyqa optimizer

control_bobyqa <- lmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 1e9))

m2 <- lmer(pupil.binned ~ poly1 + poly2 + poly3 + speaker +
             poly1*speaker +
             (poly1 + poly2 + poly3|subject), 
              data = pupil_roi, control = control_bobyqa)

summary(m2)

anova(m1, m2)


```
## Model 3

```{r}

m3 <- lmer(pupil.binned ~ poly1 + poly2 + poly3 + speaker +
             poly1*speaker + poly2*speaker +
             (poly1 + poly2 + poly3|subject), 
              data = pupil_roi, control = control_bobyqa)

summary(m3)

anova(m2, m3)


```
## Model 4

```{r}

m4 <- lmer(pupil.binned ~ poly1 + poly2 + poly3 + speaker +
             poly1*speaker + poly2*speaker + poly3*speaker +
             (poly1 + poly2 + poly3|subject), data = pupil_roi, 
           control = control_bobyqa)

summary(m4)

anova(m3, m4)

```

