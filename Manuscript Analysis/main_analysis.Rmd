---
title: "Main Analysis"
author: "Micah E. Hirsch"
date: "2024-05-13"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
    
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Purpose

The purpose of this document is to analyze and report findings related to M. Hirsch's dissertation project. The data preparation and analysis was conducted using R Version 4.3.3.

```{r, echo = F, warning = F, messsage = F}

# Load in Needed Packages

library(rio)
library(tidyverse)
library(mgcv)
library(itsadug)
library(irr)
library(ggpubr) # installl.packages("ggpubr")
library(gt) # install.packages("gt")
library(gtsummary) # install.packages("gtsummary")
library(glmmTMB) # install.packages("glmmTMB")
library(performance) # install.packages("performance")
library(sjPlot) # install.packages("sjPlot")


```


# Listener Demographics

The table below shows the demographic information for the listeners in this study. A total of 39 listeners were recruited to participate in the study. However, 1 participant withdrew from the study (their data was already destroyed before exporting the listener demographic dataset) and 4 participants were dismissed due to difficulty during the calibration phase of the study. Therefore, there ended up being 34 total listeners in this study. The demographic table shows the demographic information for the 34 participants included in the study (complete) and the 4 who were not able to be tracked by the eye-tracking camera (incomplete).

All listeners reported being a fluent speaker of English. However, two participants noted that their native language was different than American English. Their reported native languages were Turkish and Spanish.

```{r, warning = F, message = F}

demo <- rio::import("Cleaned Data/cleaned_listener_demo.csv") |>
  dplyr::mutate(gender = factor(gender, levels = c("Man", "Woman", "Nonbinary", "Questioning", "Prefer not to answer")),
                ethnicity = factor(ethnicity, levels = c("Hispanic/Latino(a/e)", "Not Hispanic/Latino(a/e)", "Prefer not to answer")),
                race = factor(race, levels = c("white/Caucasian", "Black/African American", "Asian/Asian American",
                                               "Native Hawaiian or Other Pacific Islander", "Native American or Alaska Native",
                                               "Biracial or Multiracial", "Prefer not to answer", "Race not listed")),
                native_lang = factor(native_lang, c("American English", "Not American English")))
  
demo_table <- demo |>
  dplyr::select(age, gender, ethnicity, race, native_lang, pupil_complete) |>
  tbl_strata(
    strata = pupil_complete,
    ~.x |>
      tbl_summary(type = list(age ~ "continuous",
                          gender ~ "categorical",
                          ethnicity ~ "categorical",
                          race ~ "categorical",
                          native_lang ~ "categorical"),
                  statistic = list(all_continuous() ~ "{mean} ({sd}, {min}-{max})",
                               all_categorical() ~ "{n} ({p}%)"),
                  digits = list(everything() ~ c(2)),
                  label = list(age ~ "Age",
                           gender ~ "Gender",
                           ethnicity ~ "Ethnicity",
                           race ~ "Race",
                           native_lang ~ "Native Language"))
    ) |>
  as_gt()

demo_table

demo_table |>
  gt::gtsave("Tables/demographic_table.html")

```


```{r, echo = F, warning = F, message = F}

# Removing unneeded items from the environment
rm(demo, demo_table)

```


# Descriptives

## Transcription Reliability

Phrase repetition accuracy was determined by transcriptions of the listener's spoken response. These reponses were transcribed by 2 research assistants. To determine interrater reliability, each RA transcribed at least 20% of the other RA's listener reponses. Fleiss' kappa was then used to calculated interrater reliability for the resulting phrase repetition accuracy determination (accurate or inaccurate). Based on the result below, our interrater reliability for phrase repetition accuracy was strong.

```{r, warning = F, message = F}

phrase_acc <- rio::import("Cleaned Data/repetition_accuracy.csv")

phrase_acc <- phrase_acc |>
  dplyr::mutate(rep_acc = ifelse(initial_response == "missing data", NA, 
                                 ifelse(target_number == correct_words_initial, "accurate", "inaccurate")),
                rep_acc_rel = ifelse(rel_response == "missing data", NA, 
                                 ifelse(target_number == correct_words_rel, "accurate", "inaccurate")))

reliability <- phrase_acc |>
  dplyr::filter(!is.na(rep_acc_rel)) |>
  dplyr::select(rep_acc, rep_acc_rel)

# Computing Fleiss' Kappa

kappam.fleiss(reliability, detail = T)

phrase_acc_df <- phrase_acc |>
  dplyr::select(subject, trial, target_number, correct_words_initial, rep_acc)

```

## Speaker Characteristics

The speaker characteristics are listed below. Note: 41 trials were removed because they had missing listener responses (i.e. audio file cut out, etc.). Therefore, the summary statistics are based on 2679 trials total.

```{r}

ple_data <- rio::import("Cleaned Data/cleaned_ple_data.csv") |>
  dplyr::left_join(phrase_acc_df, by = c("subject", "trial")) |>
  dplyr::mutate(speaker = factor(speaker, levels = c("Control", "ALS")),
                trial_c = trial - 6,
                rep_acc = factor(rep_acc, levels = c("accurate", "inaccurate")))

speaker_table <- ple_data |>
  dplyr::filter(!is.na(rep_acc)) |>
  dplyr::select(subject, trial, speaker, correct_words_initial, target_number, rep_acc) |>
  dplyr::mutate(intel = (correct_words_initial/target_number)*100) |>
  dplyr::select(-c(subject, trial, correct_words_initial, target_number)) |>
  tbl_summary(by = speaker,
              type = list(intel ~ "continuous",
                          rep_acc ~ "categorical"),
              statistic = list(all_continuous() ~ "{mean} ({sd})",
                               all_categorical() ~ "{n} ({p}%)"),
              digits = list(everything() ~ c(2)),
              label = list(intel ~ "Intelligibility",
                           rep_acc ~ "Repetition Accuracy")) |>
  as_gt()

speaker_table

speaker_table |>
  gt::gtsave("Tables/speaker_table.html")


```


# Perceived Listening Effort Ratings

## Descriptives

```{r, warning = F, message = F}

ple_data |>
  dplyr::select(speaker, effort_rating, rep_acc) |>
  dplyr::filter(!is.na(rep_acc)) |>
  tbl_strata(
    strata = rep_acc,
    ~.x |>
      tbl_summary(
        by = speaker,
        type = list(effort_rating ~ "continuous"),
        statistic = list(all_continuous() ~ c("{mean} ({sd})")),
        missing = "no",
        digits = all_continuous() ~ 2,
        label = list(effort_rating ~ "Perceived Listening Effort")
      ))

```

## PLE Models

Linear mixed effects (LME) models were used to test the influence of speaker (Control vs ALS) and phrase repetition accuracy (accurate vs inaccurate) on perceived listening effort ratings. We used a model-building approach for this analysis. The steps are detailed below.

### Fully Unconditional Model

```{r}

ple_data <- ple_data |>
  dplyr::filter(!is.na(rep_acc))

m0_ple <- glmmTMB(effort_rating ~ 1 + (1|subject) + (1|code), data = ple_data)
sjPlot::tab_model(m0_ple, pred.labels = "Intercept",
                  dv.labels = "Perceived Listening Effort")

performance::icc(m0_ple)

```
### PLE Model 1

In this step, we are adding trial order (trial_c) as a random slop for both the listener (subject) and phrase (code) random intercepts. The random intercept of trial order significantly improved model fit.

```{r}

m1_ple <- glmmTMB(effort_rating ~ 1 + (trial_c|subject) + (trial_c|code), data = ple_data)
sjPlot::tab_model(m1_ple, pred.labels = "Intercept",
                  dv.labels = "Perceived Listening Effort")

performance::test_performance(m0_ple, m1_ple)

```
### PLE Model 2

Trial order is the first random effect added to the model. Trial order is added in order to control for any possible order effects in the data. As noted in the results below, adding trial order did not significantly improve model fit to the data. However, I'll leave this fixed effect in the model to act as a covariate.

```{r}

m2_ple <- glmmTMB(effort_rating ~ trial_c + (trial_c|subject) + (trial_c|code), data = ple_data)
sjPlot::tab_model(m2_ple, 
                  pred.labels = c("Intercept", "Trial Order"),
                  dv.labels = "Perceived Listening Effort")

performance::test_performance(m1_ple, m2_ple)

```

### PLE Model 3

Adding the main fixed effect of speaker significantly improved the model fit.

```{r}

m3_ple <- glmmTMB(effort_rating ~ trial_c + speaker + (trial_c|subject) + (trial_c|code), data = ple_data)
sjPlot::tab_model(m3_ple,
                  pred.labels = c("Intercept", "Trial Order", "Speaker [ALS]"),
                  dv.labels = "Perceived Listening Effort")

performance::test_performance(m2_ple, m3_ple)

```

### PLE Model 4

The main fixed effect of repetition accuracy significantly improved model fit.

```{r}

m4_ple <- glmmTMB(effort_rating ~ trial_c + speaker + rep_acc + (trial_c|subject) + (trial_c|code), data = ple_data)
sjPlot::tab_model(m4_ple,
                  pred.labels = c("Intercept", "Trial Order", "Speaker [ALS]", "Repetition Accuracy [Inaccurate]"),
                  dv.labels = "Perceived Listening Effort")

performance::test_performance(m3_ple, m4_ple)


```
### PLE Model 5

The interaction term between speaker and repetition accuracy did not significantly improve model fit. This indicates that the magnitude between accurate and inaccurate ratings was similar for both speakers.

```{r}

m5_ple <- glmmTMB(effort_rating ~ trial_c + speaker + rep_acc + speaker*rep_acc + (trial_c|subject) + (trial_c|code), data = ple_data)
sjPlot::tab_model(m5_ple,
                  pred.labels = c("Intercept", "Trial Order", "Speaker [ALS]", "Repetition Accuracy [Inaccurate]",
                                  "Speaker [ALS] * Repetition Accuracy [Inaccurate]"),
                  dv.labels = "Perceived Listening Effort")

performance::test_performance(m4_ple, m5_ple)


```

## Plot

```{r}

model_ple <- m5_ple |>
  sjPlot::plot_model(type = "int")

plot_data_ple <- model_ple[["data"]] |>
  as.data.frame()  

```


# Pupil Dilation

```{r}



```


