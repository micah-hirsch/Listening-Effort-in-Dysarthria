# Transcription Data Preprocessing

# Author: Micah E. Hirsch, M.S., mhirsch@fsu.edu

# Date: 5/7/2024 

## Purpose: To load in transcriptions of the listener responses,
## determine phrase recognition accuracy, and merge with the pupil data
## (both raw and normalized pupil dfs). 

# Loading Required Packages

library(rio) # install.packages("rio")
library(tidyverse) # install.packages("tidyverse")
# Remotes is needed to download autoscore
library(remotes) # install.packages("remotes")
library(autoscore) # remotes::install_github("autoscore/autoscore")
library(SnowballC) # install.packages("SnowballC")

# Set working directory to load data

setwd("~/Documents/Listening-Effort-in-Dysarthria/Raw Data")

# Loading in raw transcriptions

transcriptions <- rio::import("transcriptions.csv", header = T)

# Preparing the script for scoring

transcriptions <- transcriptions |>
  # Fixing a data entry error 
  dplyr::mutate(ID = case_when(ResponseId == "R_3l45R7NRdSEXrTr" ~ "LE24",
                               TRUE ~ ID)) |>
  # Removing unneeded columns generated by Qualtrics
  dplyr::select(!c(StartDate:UserLanguage, Counter_List)) |>
  # Removing first two rows
  dplyr::filter(grepl("LE", ID)) |>
  dplyr::filter(!grepl("Participant", ID)) |>
  # LE01 has multiple submissions. Only keeping the completed submission.
  dplyr::filter(`85` != "") 
  
initial <- transcriptions |>
  # selecting initial transcriptions only
  dplyr::filter(Time == "Initial Transcription") |>
  dplyr::select(!RA) |>
  # converting df to long format
  tidyr::pivot_longer(cols = "1":"85",
                      names_to = "trial",
                      values_to = "response") |>
  dplyr::rename(id = ID) |>
  # formatting trial and response variables
  dplyr::mutate(trial = as.numeric(trial),
                response = tolower(response),
                response = trimws(response, "both")) |>
  # Removing first 5 trials since these are practice
  dplyr::filter(!trial %in% (1:5)) |>
  # Some audio files were cut off but not marked during transcriptions
  dplyr::mutate(response = case_when(id == "LE21" & trial %in% c(20, 34, 41, 50, 54, 55, 81) ~ "missing data",
                                     id == "LE22" & trial %in% c(25, 26, 47, 57, 62, 64) ~ "missing data",
                                     id == "LE23" & trial == 13 ~ "missing data",
                                     TRUE ~ response))
  
reliability <- transcriptions |>
  dplyr::filter(Time == "Second Transcription") |>
  dplyr::select(!RA) |>
  # converting df to long format
  tidyr::pivot_longer(cols = "1":"85",
                      names_to = "trial",
                      values_to = "response") |>
  dplyr::rename(id = ID) |>
  # formatting trial and response variables
  dplyr::mutate(trial = as.numeric(trial),
                response = tolower(response),
                response = trimws(response, "both")) |>
  # Removing first 5 trials since these are practice
  dplyr::filter(!trial %in% (1:5))


# Calculating phrase accuracy 

## Set working directory to location of cleaned pupil data
setwd("~/Documents/Listening-Effort-in-Dysarthria/Manuscript Analysis/Cleaned Data")

pupil <- rio::import("cleaned_pupil_data.csv")

## Getting phrase targets
targets <- pupil |>
  dplyr::rename(id = subject,
                target = targetphrase) |>
  dplyr::select(id, trial, target) |>
  distinct() |>
  # Added this code to ensure targets variable is formatted correctly
  dplyr::mutate(target = tolower(target),
                target = trimws(target, "both"))

## Merging targets with the initial transcriptions
phrase_acc_initial <- targets |>
  dplyr::left_join(initial, by = c("id", "trial")) |>
  ## Count number of words in target phrase
  dplyr::mutate(target_number = str_count(target, "\\S+")) 

## Merging targets with the reliability transcriptions
phrase_acc_rel <- targets |>
  dplyr::left_join(reliability, by = c("id", "trial")) |>
  ## Count number of words in target phrase
  dplyr::mutate(target_number = str_count(target, "\\S+")) |>
  dplyr::filter(!is.na(response))

## Counting number of correctly recognized words for initial transcriptions
phrase_acc_initial <- autoscore::autoscore(
  phrase_acc_initial,
  acceptable_df = autoscore::acceptable_spellings,
  plural_rule = T,
  plural_add_rule = T,
  tense_rule = T,
  tense_add_rule = T,
  a_the_rule = T,
  double_letter_rule = T) 

phrase_acc_initial <- phrase_acc_initial |>
  dplyr::rename(correct_words_initial = autoscore,
                initial_response = response) |>
  dplyr::select(!time)


## Counting number of correctly recognized words for reliability transcriptions
phrase_acc_rel <- autoscore::autoscore(
  phrase_acc_rel,
  acceptable_df = autoscore::acceptable_spellings,
  plural_rule = T,
  plural_add_rule = T,
  tense_rule = T,
  tense_add_rule = T,
  a_the_rule = T,
  double_letter_rule = T) 

phrase_acc_rel <- phrase_acc_rel |>
  dplyr::rename(correct_words_rel = autoscore,
                rel_response = response) |>
  dplyr::select(!time)


# Creating dichotomous phrase repetition accuracy variable

## There are some trials with missing transcription data. The lab RAs coded these 
## transcriptions with missing data. Therefore, this section of code is going to check to see
## if the response variable contains "missing data". If it does, then repetition
## accuracy will be set to NA. Otherwise, repetition accuracy will be determined 
## as "accurate" or "inaccurate" for the remaining trials.


phrase_acc <- phrase_acc_initial |>
  ## Combining initial and reliability transcriptions
  dplyr::left_join(phrase_acc_rel, by = c("id", "target", "trial", "target_number")) |>
  dplyr::mutate(rep_acc = ifelse(initial_response == "missing data", NA, 
                                 ifelse(target_number == correct_words_initial, "accurate", "inaccurate")),
                rep_acc_rel = ifelse(rel_response == "missing data", NA, 
                                 ifelse(target_number == correct_words_rel, "accurate", "inaccurate"))) |>
  dplyr::rename(subject = id,
                targetphrase = target)

# Export csv file of cleaned data

rio::export(phrase_acc, "repetition_accuracy.csv")

